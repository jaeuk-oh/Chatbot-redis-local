{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4db3e7b7",
      "metadata": {
        "id": "4db3e7b7"
      },
      "source": [
        "## 1.í™˜ê²½ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d6b0bd",
      "metadata": {
        "id": "c6d6b0bd"
      },
      "source": [
        "### 1-1.í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "684877f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "684877f3",
        "outputId": "2c5a7834-acdc-4a7a-f7b8-251ddbab7f20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~angchain-community (C:\\Users\\user\\.llmenv\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~angchain-community (C:\\Users\\user\\.llmenv\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~angchain-community (C:\\Users\\user\\.llmenv\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~angchain-community (C:\\Users\\user\\.llmenv\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain langchain-core langchain-community langchain-upstage \\\n",
        "redis pandas python-dotenv tqdm datasets huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b98e7e0d",
      "metadata": {
        "id": "b98e7e0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\.llmenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from huggingface_hub import (\n",
        "    HfApi, create_repo, repo_exists, upload_folder,\n",
        "    list_repo_files, hf_hub_download\n",
        ")\n",
        "from datasets import load_dataset\n",
        "\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1) Redisë¥¼ LangChain Community ëª¨ë“ˆë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
        "\n",
        "# 2) í…ŒìŠ¤íŠ¸ LLMì„ LangChainìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°(Upstage ChatUpstage)\n",
        "from langchain_upstage import ChatUpstage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d1702",
      "metadata": {
        "id": "022d1702"
      },
      "source": [
        "### 1-2.í™˜ê²½ì„¤ì • ë³€ìˆ˜ ì„¤ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d39b43a5",
      "metadata": {
        "id": "d39b43a5"
      },
      "source": [
        "- .env file ì˜ˆì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad526f1",
      "metadata": {
        "id": "4ad526f1"
      },
      "outputs": [],
      "source": [
        "# # Redis\n",
        "# REDIS_URL=redis://localhost:6379\n",
        "# KEY_PREFIX=message_store:        # LangChain ê¸°ë³¸ prefix (ë°”ê¿¨ìœ¼ë©´ ë§ê²Œ)\n",
        "# SESSION_IDS=sesac,devtest        # ì½¤ë§ˆë¡œ ì—¬ëŸ¬ ì„¸ì…˜ ì§€ì • (ìë™íƒìƒ‰ ì•ˆ ì“°ëŠ” ê°„ë‹¨ ë°©ì‹)\n",
        "\n",
        "# # Local export\n",
        "# OUTPUT_DIR=llm_sessions\n",
        "\n",
        "# # Upstage\n",
        "# UPSTAGE_API_KEY=upstage_xxx\n",
        "# SOLAR_MODEL=solar-pro         # í•„ìš”ì‹œ solar-pro-2 ë“±\n",
        "\n",
        "# HF_DATASET_REPO=your-username/llm-chat-sessions\n",
        "# HF_TOKEN=hf_xxx\n",
        "# HF_PRIVATE=true\n",
        "# LOCAL_CSV_DIR=llm_sessions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1672f590",
      "metadata": {},
      "outputs": [],
      "source": [
        "# redis ì—ì„œ session_idë¥¼ ì¶”ì¶œí•´ì„œ env íŒŒì¼ë¡œ \n",
        "import redis\n",
        "\n",
        "r = redis.Redis(host='localhost', port=6379, db=0)\n",
        "keys = r.keys(pattern=\"message_store:*\")\n",
        "\n",
        "# redisëŠ” ë‚´ë¶€ì ìœ¼ë¡œ bytesë¡œ ì €ì¥í•œë‹¤. ë°”ë¡œ strì²˜ëŸ¼ split ì•ˆ ë¨. decoding í•´ì•¼í•¨.\n",
        "session_ids = [key.decode().split(':')[1] for key in keys]\n",
        "\n",
        "# envì— í™˜ê²½ë³€ìˆ˜ ë“±ë¡í•  ë•ŒëŠ” strë§Œ ëœë‹¤.\n",
        "os.environ['SESSION_IDS'] = ','.join(session_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "40e98d5e",
      "metadata": {
        "id": "40e98d5e"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
        "KEY_PREFIX = os.getenv(\"KEY_PREFIX\", \"message_store:\")\n",
        "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"llm_sessions\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")  # ChatUpstageê°€ envë¡œ ì½ìŒ\n",
        "SOLAR_MODEL = os.getenv(\"SOLAR_MODEL\", \"solar-pro2\")\n",
        "\n",
        "# ì„¸ì…˜ID ëª©ë¡: ì½¤ë§ˆ êµ¬ë¶„\n",
        "# envì— ë³€ìˆ˜ë¡œ ë“±ë¡í•  ë•ŒëŠ” strì´ë¼ ì—¬ê¸°ì„œ splitìœ¼ë¡œ ë‹¤ì‹œ listë¡œ ë°”ê¿”ì„œ ë½‘ëŠ”ë‹¤.\n",
        "# if s.strip() -> s (=id)ê°€ ê³µë°± ì œê±°í–ˆì„ ë•Œ falseê°€ ì•„ë‹ˆë¼ë©´ (= sê°€ ê³µë°±ì´ ì•„ë‹ˆë¼ë©´) í¬í•¨í•´ë¼\n",
        "SESSION_IDS = [s.strip() for s in os.getenv(\"SESSION_IDS\", \"\").split(',') if s.strip()]\n",
        "\n",
        "HF_REPO   = os.getenv(\"HF_DATASET_REPO\", \"jaewook/llm-chat-sessions\")          # ì˜ˆ: your-username/llm-chat-sessions\n",
        "HF_TOKEN  = os.getenv(\"HF_TOKEN\")\n",
        "HF_PRIVATE = str(os.getenv(\"HF_PRIVATE\", \"true\")).lower() == \"true\"\n",
        "LOCAL_DIR = os.getenv(\"LOCAL_CSV_DIR\", \"llm_sessions\")  # ì„¸ì…˜ë³„ CSV í´ë”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe38b2f",
      "metadata": {
        "id": "0fe38b2f"
      },
      "source": [
        "## 2.Redis ì—ì„œ chat data ë¶ˆëŸ¬ì™€ì„œ csv file ë¡œ ì €ì¥í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47099603",
      "metadata": {
        "id": "47099603"
      },
      "source": [
        "### 2-1. Redis ì—ì„œ session id ë¡œ chat data ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "44054ad9",
      "metadata": {
        "id": "44054ad9"
      },
      "outputs": [],
      "source": [
        "def _messages_to_rows(history) -> List[Dict[str, Any]]:\n",
        "    \"\"\"LangChain BaseMessage -> í‘œì¤€ dict ë¦¬ìŠ¤íŠ¸(role, content, timestamp)\"\"\"\n",
        "    rows = []\n",
        "    for m in history.messages:\n",
        "        role = getattr(m, \"type\", None) or m.__class__.__name__.replace(\"Message\", \"\").lower()\n",
        "        content = m.content\n",
        "        timestamp = None\n",
        "        # additional_kwargsì— timestampë¥¼ ë„£ì–´ë’€ë‹¤ë©´ êº¼ëƒ„\n",
        "        try:\n",
        "            timestamp = (m.additional_kwargs or {}).get(\"timestamp\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        rows.append({\"role\": role, \"content\": content, \"timestamp\": timestamp})\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bf010650",
      "metadata": {
        "id": "bf010650"
      },
      "outputs": [],
      "source": [
        "def _messages_to_text(rows: List[Dict[str, Any]]) -> str:\n",
        "    lines = []\n",
        "    for r in rows:\n",
        "        role = (r.get(\"role\") or \"user\").upper()\n",
        "        content = r.get(\"content\") or \"\"\n",
        "        lines.append(f\"{role}: {content}\")\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "14b79628",
      "metadata": {
        "id": "14b79628"
      },
      "outputs": [],
      "source": [
        "def _chunk_text(text: str, chunk_size: int = 4000) -> List[str]:\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        chunks.append(text[i:i+chunk_size])\n",
        "        i += chunk_size\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "96e49619",
      "metadata": {
        "id": "96e49619",
        "outputId": "69c0c5c7-f276-4f7f-dadb-8e41d9af5d6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exporting sessions:   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exporting sessions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 105.17it/s]\n"
          ]
        }
      ],
      "source": [
        "historys = []\n",
        "for sid in tqdm(SESSION_IDS, desc=\"Exporting sessions\"):\n",
        "        history = RedisChatMessageHistory(\n",
        "            session_id=sid,\n",
        "            url=REDIS_URL,\n",
        "            key_prefix=KEY_PREFIX\n",
        "        )\n",
        "        historys.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d084d1d0",
      "metadata": {
        "id": "d084d1d0",
        "outputId": "29b60aab-f1d9-4abd-dddb-a773fa9e1d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 content='ì•ˆë…•' additional_kwargs={} response_metadata={}\n",
            "1 content='ì•ˆë…•í•˜ì„¸ìš©ğŸ€' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'solar-mini-250422'} id='run--5ffe59f4-776a-40a4-934e-178c8845e0c6-0'\n",
            "2 content='í˜„ì¬ ì‹œê°„ì€?' additional_kwargs={} response_metadata={}\n",
            "3 content='ì§€ê¸ˆ ì‹œê°„ì€ ë¹„ë°€ğŸ€ (ë†ë‹´ì´ì•¼~ ì§€ê¸ˆ ë‹¹ì¥ ì•Œë ¤ì¤„ê²Œ! ë¿…!)' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'solar-mini-250422'} id='run--dd76b7d0-1a7b-4bfc-822d-02c9db3293e9-0'\n",
            "4 content='ì•Œë ¤ì¤˜' additional_kwargs={} response_metadata={}\n",
            "5 content='ìŒ... ì§€ê¸ˆì€ \"ë„ˆë‘ ë†€ ì‹œê°„!\" ë¿…ğŸ€' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'solar-mini-250422'} id='run--8e05e8d5-4ea1-4409-a4ec-e287805c92b4-0'\n",
            "6 content='attention maskê°€ ë­ì•¼?' additional_kwargs={} response_metadata={}\n",
            "7 content='Attention maskëŠ” ë¨¸ì‹  ëŸ¬ë‹ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë§ˆë²•ì˜ ë§ˆìŠ¤í¬ì•¼! íŠ¹ì • ë¶€ë¶„ì— ì§‘ì¤‘í•˜ê²Œ ë„ì™€ì¤˜ ğŸ‘€ğŸ€' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'solar-mini-250422'} id='run--e732a296-4e6d-41e0-bcff-26a0a84ed195-0'\n",
            "8 content='ì „ë¬¸ê°€ì²˜ëŸ¼ ì•Œë ¤ì¤˜' additional_kwargs={} response_metadata={}\n",
            "9 content='Attention maskëŠ” Transformer ì•„í‚¤í…ì²˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¤‘ìš”í•œ ê°œë…ì´ì•¼. ì£¼ë¡œ ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜(Self-Attention)ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ìœ„ì¹˜(íŒ¨ë”© ë“±)ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ì‚¬ìš©ë˜ì§€. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ë°ì´í„°ì—ë§Œ ì§‘ì¤‘í•˜ê²Œ í•´ì£¼ê³ , ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì— ê³„ì‚° ë¦¬ì†ŒìŠ¤ë¥¼ ë‚­ë¹„í•˜ì§€ ì•Šë„ë¡ ë„ì™€ì¤˜. ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—­í• ì„ í•˜ì§€. ğŸ§™\\u200dâ™‚ï¸ğŸ€' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'solar-mini-250422'} id='run--bc9b317b-9f2a-4f88-b78f-cb92a414b8c6-0'\n"
          ]
        }
      ],
      "source": [
        "for i,mes in enumerate(historys[3].messages):\n",
        "    print(i,mes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788472c4",
      "metadata": {
        "id": "788472c4"
      },
      "source": [
        "### 2-2. ë‚˜ëˆ´ë˜ ëŒ€í™” csv file ë¡œ ì €ì¥í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "76ec3849",
      "metadata": {
        "id": "76ec3849",
        "outputId": "7fc923cf-7b1d-42d7-d8fe-b9e7b8ae3e88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exporting sessions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 29.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] 7ê°œ ì„¸ì…˜ CSV ì €ì¥ -> llm_sessions/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    if not SESSION_IDS:\n",
        "            raise SystemExit(\n",
        "                \"SESSION_IDS(.env)ì„ ì§€ì •í•˜ì„¸ìš”. ì˜ˆ) SESSION_IDS=sesac,project42\"\n",
        "            )\n",
        "\n",
        "    session_csv_paths = {}\n",
        "\n",
        "    # Redis(LangChain Community)ë¡œ ì„¸ì…˜ë³„ ëŒ€í™” ë¶ˆëŸ¬ì™€ CSV ì €ì¥\n",
        "    for sid in tqdm(SESSION_IDS, desc=\"Exporting sessions\"):\n",
        "        history = RedisChatMessageHistory(\n",
        "            session_id=sid,\n",
        "            url=REDIS_URL,\n",
        "            key_prefix=KEY_PREFIX\n",
        "        )\n",
        "        rows = _messages_to_rows(history)\n",
        "        df = pd.DataFrame(rows)\n",
        "        csv_path = os.path.join(OUTPUT_DIR, f\"{sid}.csv\")\n",
        "        df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
        "        session_csv_paths[sid] = csv_path\n",
        "\n",
        "    print(f\"[OK] {len(session_csv_paths)}ê°œ ì„¸ì…˜ CSV ì €ì¥ -> {OUTPUT_DIR}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "916c7d45",
      "metadata": {
        "id": "916c7d45"
      },
      "source": [
        "## 3. ì´ì „ì— ë‚˜ëˆˆ ëŒ€í™” ìš”ì•½í•´ì„œ ì €ì¥í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "21c4fe76",
      "metadata": {
        "id": "21c4fe76"
      },
      "outputs": [],
      "source": [
        "def get_llm(temperature: float = 0.0) -> ChatUpstage:\n",
        "    # UPSTAGE_API_KEY í•„ìš”. ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ.\n",
        "    return ChatUpstage(model=SOLAR_MODEL, temperature=temperature)\n",
        "\n",
        "SUMMARIZE_SYSTEM = (\n",
        "    \"ë„ˆëŠ” ì „ë¬¸ ìš”ì•½ê°€ë‹¤. ë‹¤ìŒ ëŒ€í™”ë¥¼ 400~600ë‹¨ì–´ ë‚´ë¡œ ìš”ì•½í•˜ë˜, \"\n",
        "    \"1) ì˜ë„/ë§¥ë½ 2) í•µì‹¬ í¬ì¸íŠ¸ 3) ê²°ì •ì‚¬í•­ 4) To-Do 5) ì—´ë¦° ì´ìŠˆ ë¥¼ êµ¬ì¡°í™”í•´ë¼. í•œêµ­ì–´ë¡œ.\"\n",
        ")\n",
        "\n",
        "def summarize_text(text: str) -> str:\n",
        "    \"\"\"ê¸´ ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ mapâ†’reduceë¡œ ìš”ì•½\"\"\"\n",
        "    llm_map = get_llm(0.0)\n",
        "    llm_reduce = get_llm(0.0)\n",
        "\n",
        "    map_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", SUMMARIZE_SYSTEM),\n",
        "        (\"human\", \"ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•˜ë¼:\\n\\n{chunk}\")\n",
        "    ])\n",
        "    map_chain = map_prompt | llm_map | StrOutputParser()\n",
        "\n",
        "    reduce_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", SUMMARIZE_SYSTEM),\n",
        "        (\"human\", \"ë‹¤ìŒ ë¶€ë¶„ ìš”ì•½ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ë¼:\\n\\n{parts}\")\n",
        "    ])\n",
        "    reduce_chain = reduce_prompt | llm_reduce | StrOutputParser()\n",
        "\n",
        "    chunks = _chunk_text(text, chunk_size=3500)\n",
        "    parts = [map_chain.invoke({\"chunk\": c}) for c in chunks] if chunks else [\"\"]\n",
        "    merged = reduce_chain.invoke({\"parts\": \"\\n\\n---\\n\\n\".join(parts)})\n",
        "    return merged.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2a61ad3c",
      "metadata": {
        "id": "2a61ad3c"
      },
      "outputs": [],
      "source": [
        "def ask_with_summary(summary_doc: str, query: str) -> str:\n",
        "    llm = get_llm(0.2)\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"ë„ˆëŠ” ìœ ëŠ¥í•œ í•œêµ­ì–´ ë¹„ì„œë‹¤. ì œê³µëœ 'ì´ì „ ëŒ€í™” ìš”ì•½'ì„ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•´ë¼.\"),\n",
        "        (\"human\", \"[ì´ì „ ëŒ€í™” ìš”ì•½]\\n{summary}\\n\\n[ì§ˆë¬¸]\\n{query}\")\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return chain.invoke({\"summary\": summary_doc, \"query\": query}).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "361fc9ef",
      "metadata": {
        "id": "361fc9ef",
        "outputId": "1d62a16d-b4eb-4938-c956-4a97174a5a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ìš”ì•½ë¬¸ ë¯¸ë¦¬ë³´ê¸°]\n",
            " ### **í†µí•© ìš”ì•½: ì—…ìŠ¤í…Œì´ì§€ ë° AI ê´€ë ¨ ì •ë³´ êµí™˜**  \n",
            "\n",
            "#### **1. ì˜ë„/ë§¥ë½**  \n",
            "ì‚¬ìš©ìëŠ” AI ëª¨ë¸ \"ì†”ë¼\"ì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ **ì—”ë¹„ë””ì•„ íšŒì¥ ì´ë¦„**, **ì—…ìŠ¤í…Œì´ì§€ì˜ ëŒ€í‘œ ë° ì—°í˜**, **ê¸°ìˆ  ì„±ê³¼ì™€ ì£¼ìš” ì‚¬ì—…**ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í–ˆë‹¤. AIëŠ” ìºì£¼ì–¼í•œ ì–´ì¡°(ì´ëª¨ì§€ í¬í•¨)ë¡œ ë‹µë³€í•˜ë©°, ì—…ìŠ¤í…Œì´ì§€ì˜ ê¸°ìˆ ë ¥ê³¼ ì†”ë¼ ëª¨ë¸ì˜ ì—­í• ì„ ê°•ì¡°í–ˆë‹¤. ì´ ëŒ€í™”ëŠ” ì—…ìŠ¤í…Œì´ì§€ì— ëŒ€í•œ ê¸°ë³¸ ì´í•´ë¥¼ ëª©ì ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìœ¼ë‚˜, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ê³µì‹ ë°ì´í„° ë¶€ì¬ë¡œ ì¸í•´ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•œ ìƒí™©ì´ë‹¤.  \n",
            "\n",
            "#### **2. í•µì‹¬ í¬ì¸íŠ¸**  \n",
            "- **ì—”ë¹„ë””ì•„ íšŒì¥**: ì  ìŠ¨ í™©(Jensen Huang).  \n",
            "- **ì—…ìŠ¤í…Œì´ì§€ ëŒ€í‘œ**: ê¹€ì„±í›ˆ.  \n",
            "- **ì—…ìŠ¤í…Œì´ì§€ ì—°í˜**:  \n",
            "  - ì°½ë¦½ í›„ AI ëª¨ë¸ \"ì†”ë¼\" ê°œë°œ â†’ í˜„ì¬ ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš© ë‹¨ê³„.  \n",
            "- **ì—…ìŠ¤í…Œì´ì§€ì˜ ì„±ê³¼**:  \n",
            "  - ê¸€ë¡œë²Œ AI ëª¨ë¸ \"ì†”ë¼\" ì¶œì‹œ ë° ëŒ€ì¤‘í™”.  \n",
            "  - ê¸°ì—…ìš© AI ì†”ë£¨ì…˜(ì˜ˆ: ì†”ë¼) ì œê³µ.  \n",
            "- **ì£¼ìš” ì‚¬ì—…**:  \n",
            "  - ê¸°ì—… ëŒ€ìƒ AI ê¸°ìˆ  ê°œë°œ ë° ì†”ë£¨ì…˜ ê³µê¸‰.  \n",
            "  - ì‚¬ìš©ì ì¹œí™”ì ì¸ AI ëª¨ë¸(ì†”ë¼)ì„ í†µí•œ ì„œë¹„ìŠ¤ í™•ì¥.  \n",
            "\n",
            "#### **3. ê²°ì •ì‚¬í•­**  \n",
            "- ì‚¬ìš©ìëŠ” ì—…ìŠ¤í…Œì´ì§€ì™€ ì†”ë¼ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ë¥¼ í™•ì¸í–ˆìœ¼ë©°, AIì˜ ë‹µë³€ì—ì„œ **ê¸°ìˆ ë ¥ê³¼ ì†”ë¼ ëª¨ë¸ì˜ ì—­í• **ì„ ì¸ì§€í–ˆë‹¤.  \n",
            "- AIëŠ” ì—…ìŠ¤í…Œì´ì§€ì˜ ì„±ê³¼ë¥¼ ê°•ì¡°í•˜ë©°, ì‚¬ìš©ìì™€ì˜ ì§€ì†ì  ìƒí˜¸ì‘ìš© ê°€ëŠ¥ì„±ì„ ì•”ì‹œí–ˆë‹¤.  \n",
            "\n",
            "#### **4. To-Do**  \n",
            "- **ì‚¬ìš©ì**:  \n",
            "  - ì—…ìŠ¤í…Œì´ì§€ ê³µì‹ ì±„ë„(ì›¹ì‚¬ì´íŠ¸, SNS)ì—ì„œ ì¬ì • í˜„í™©, íŒŒíŠ¸ë„ˆì‹­, ì •ëŸ‰ì  ì„±ê³¼(ì‚¬ìš©ì ìˆ˜, ì‹œì¥ ì ìœ ìœ¨) ë“± ì¶”ê°€ ì •ë³´ í™•ì¸.  \n",
            "  - ì†”ë¼ ëª¨ë¸ì˜ êµ¬ì²´ì  ê¸°ëŠ¥(ì–¸ì–´ ì²˜ë¦¬, ë©€í‹°ëª¨ë‹¬ ëŠ¥ë ¥) ë° ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­(ëª¨ë¸ ì•„í‚¤í…ì²˜, í•™ìŠµ ë°ì´í„°) ì¡°ì‚¬.  \n",
            "- **AI/ì—…ìŠ¤í…Œì´ì§€**:  \n",
            "  - ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•´ ì†”ë¼ ëª¨ë¸ì˜ ì •í™•ì„± ë° ì „ë¬¸ì„± ê°œì„ .  \n",
            "  - ê¸°ì—…ìš© ì†”ë£¨ì…˜ì˜ ì‚¬ë¡€ ì—°êµ¬ ë˜ëŠ” ë°ëª¨ ìë£Œ  ...\n",
            "\n",
            "[ì‘ë‹µ]\n",
            " ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ 3ê°€ì§€ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤:  \n",
            "\n",
            "1. **ì—…ìŠ¤í…Œì´ì§€ ê³µì‹ ì±„ë„ ê²€ì¦**  \n",
            "   - ì›¹ì‚¬ì´íŠ¸, ë°±ì„œ, ë³´ë„ìë£Œ ë“±ì„ í†µí•´ ì¬ì • í˜„í™©, íŒŒíŠ¸ë„ˆì‹­, ì •ëŸ‰ì  ì„±ê³¼(ì‚¬ìš©ì ìˆ˜, ì‹œì¥ ì ìœ ìœ¨) í™•ì¸.  \n",
            "   - ì†”ë¼ ëª¨ë¸ì˜ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­(ì•„í‚¤í…ì²˜, í•™ìŠµ ë°ì´í„°, ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬) ì¡°ì‚¬.  \n",
            "\n",
            "2. **ì†”ë¼ ëª¨ë¸ í”¼ë“œë°± ì œì¶œ**  \n",
            "   - ìºì£¼ì–¼í•œ ì–´ì¡°ì™€ ì „ë¬¸ì„± ê°„ ê· í˜•ì„ ìœ„í•œ ì‚¬ìš©ì ì˜ê²¬ ê³µìœ  (ì˜ˆ: \"ë¹„í˜•ì‹ì  í‘œí˜„ ê°ì†Œ ìš”ì²­\" ë˜ëŠ” \"ê¸°ìˆ ì  ì„¤ëª… ì¶”ê°€ ìš”ì²­\").  \n",
            "   - ê¸°ì—…ìš© ì†”ë£¨ì…˜ ì‚¬ë¡€ ë˜ëŠ” ë°ëª¨ ìë£Œ ìš”ì²­ìœ¼ë¡œ ì‹ ë¢°ì„± ê²€ì¦.  \n",
            "\n",
            "3. **AI ì—­í•  ì •ì²´ì„± ëª…í™•í™”**  \n",
            "   - ì—…ìŠ¤í…Œì´ì§€ì˜ B2B/B2C ì „ëµì„ ê³µì‹ ì±„ë„ì—ì„œ ì¬í™•ì¸ (ì˜ˆ: \"ì†”ë¼ì˜ ì£¼ìš” íƒ€ê²Ÿì€ ê¸°ì—…ì¸ê°€ ê°œì¸ ì‚¬ìš©ìì¸ê°€?\").  \n",
            "   - í–¥í›„ ëŒ€í™”ì—ì„œ ì „ë¬¸ì„± ê°•ì¡°ë¥¼ ìœ„í•œ ì–´ì¡° ì¡°ì • ìš”ì²­ (ì˜ˆ: \"ê¸°ìˆ  ì„¤ëª… ì‹œ ì´ëª¨ì§€ ìƒëµ\").  \n",
            "\n",
            "> âœ… **ëª©ì **: ì •ë³´ì˜ ì •í™•ì„± í–¥ìƒ + AI ëª¨ë¸ì˜ ì‹ ë¢°ì„± ê°•í™” + ì‚¬ìš©ì ê²½í—˜ ìµœì í™”.\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ LLM(ChatUpstage)ìœ¼ë¡œ ìš”ì•½ + ì§ˆì˜ ë°ëª¨\n",
        "# ì„¸ì…˜ì„ í•˜ë‚˜ ê³¨ë¼ ìš”ì•½ í›„, ì§ˆë¬¸ ì˜ˆì‹œ ì‹¤í–‰\n",
        "first_sid = SESSION_IDS[0]\n",
        "df = pd.read_csv(session_csv_paths[first_sid])\n",
        "text = _messages_to_text(df.to_dict(orient=\"records\"))\n",
        "\n",
        "summary = summarize_text(text)\n",
        "print(\"\\n[ìš”ì•½ë¬¸ ë¯¸ë¦¬ë³´ê¸°]\\n\", summary[:1000], \"...\\n\")\n",
        "\n",
        "answer = ask_with_summary(summary, query=\"ì´ ëŒ€í™”ì˜ ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ 3ê°€ì§€ë§Œ ì œì•ˆí•´ì¤˜.\")\n",
        "print(\"[ì‘ë‹µ]\\n\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842764b2",
      "metadata": {
        "id": "842764b2"
      },
      "source": [
        "## 4. csv file HFdataset ì— ì—…ë¡œë“œí•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8f18de",
      "metadata": {
        "id": "ac8f18de"
      },
      "outputs": [],
      "source": [
        "def upload_csv_folder_to_hf(LOCAL_DIR: str, repo_id: str, private: bool, token: str):\n",
        "    \"\"\"CSV í´ë”ë¥¼ HF dataset ë ˆí¬ì˜ /csv/ ê²½ë¡œì— ì—…ë¡œë“œ (ë ˆí¬ ì—†ìœ¼ë©´ ìƒì„±)\"\"\"\n",
        "    if not repo_id:\n",
        "        raise ValueError(\"HF_DATASET_REPO(.env)ì„ ì§€ì •í•˜ì„¸ìš”. e.g. your-username/llm-chat-sessions\")\n",
        "    if not os.path.isdir(LOCAL_DIR):\n",
        "        raise FileNotFoundError(f\"ë¡œì»¬ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {LOCAL_DIR}\")\n",
        "\n",
        "    api = HfApi(token=token)\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ë ˆí¬ ì—†ìœ¼ë©´ ìƒì„±\n",
        "    if not repo_exists(repo_id, repo_type=\"dataset\", token=token):\n",
        "        create_repo(repo_id, repo_type=\"dataset\", private=private, token=token)\n",
        "        print(f\"[HF] ë ˆí¬ ìƒì„±: https://huggingface.co/datasets/{repo_id}\")\n",
        "    else:\n",
        "        print(f\"[HF] ë ˆí¬ ì¡´ì¬: https://huggingface.co/datasets/{repo_id}\")\n",
        "\n",
        "    # í´ë” ì—…ë¡œë“œ â†’ ë ˆí¬ ë‚´ ê²½ë¡œëŠ” /csv\n",
        "    upload_folder(\n",
        "        repo_id=repo_id,\n",
        "        repo_type=\"dataset\",\n",
        "        folder_path=LOCAL_DIR,\n",
        "        path_in_repo=\"csv\",\n",
        "        token=token,\n",
        "    )\n",
        "    print(f\"[HF] ì—…ë¡œë“œ ì™„ë£Œ: {LOCAL_DIR} â†’ {repo_id}/csv/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05dffed",
      "metadata": {
        "id": "c05dffed"
      },
      "outputs": [],
      "source": [
        "# 1) ì—…ë¡œë“œ\n",
        "upload_csv_folder_to_hf(LOCAL_DIR, HF_REPO, HF_PRIVATE, HF_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b04247",
      "metadata": {
        "id": "35b04247"
      },
      "source": [
        "## 5. ì €ì¥í–ˆë˜ HF dataset ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a66464c",
      "metadata": {
        "id": "5a66464c"
      },
      "outputs": [],
      "source": [
        "def load_csv_dataset_from_hf(repo_id: str, token: str):\n",
        "    \"\"\"\n",
        "    HF ë°ì´í„°ì…‹ ë ˆí¬ì˜ /csv/*.csv íŒŒì¼ë“¤ì„ ëª¨ë‘ ë°›ì•„ì„œ í•˜ë‚˜ì˜ split('all')ë¡œ ë¡œë“œ.\n",
        "    í•„ìš”í•˜ë©´ ì„¸ì…˜ë³„ë¡œ splitì„ ë‚˜ëˆ„ëŠ” ë¡œì§ë„ ì¶”ê°€ ê°€ëŠ¥.\n",
        "    \"\"\"\n",
        "    files = list_repo_files(repo_id=repo_id, repo_type=\"dataset\", token=token)\n",
        "    csv_files = [f for f in files if f.startswith(\"csv/\") and f.lower().endswith(\".csv\")]\n",
        "    if not csv_files:\n",
        "        raise RuntimeError(\"ë ˆí¬ì— csv/*.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.\")\n",
        "\n",
        "    # ì›ê²© csvë“¤ì„ ë¡œì»¬ë¡œ ë‚´ë ¤ë°›ì•„ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±\n",
        "    local_paths = [hf_hub_download(repo_id=repo_id, repo_type=\"dataset\", filename=f, token=token)\n",
        "                   for f in csv_files]\n",
        "\n",
        "    # huggingface datasetsë¡œ í†µí•© ë¡œë“œ\n",
        "    ds = load_dataset(\"csv\", data_files={\"all\": local_paths})\n",
        "    print(f\"[HF] ë¡œë“œ ì™„ë£Œ: splits={list(ds.keys())}, rows={len(ds['all'])}\")\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d1de6f",
      "metadata": {
        "id": "e5d1de6f"
      },
      "outputs": [],
      "source": [
        "# 2) ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "ds = load_csv_dataset_from_hf(HF_REPO, HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d030895",
      "metadata": {
        "id": "0d030895"
      },
      "outputs": [],
      "source": [
        "df = ds[\"all\"].to_pandas() # íŒë‹¤ìŠ¤ë¡œ ë³€í™˜\n",
        "print(df.head(3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".llmenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
